# -*- coding: utf-8 -*-
"""диплом.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y1ZWh-_7m4qdE9phy6Dolmi5pMacMSOp

# 1 Загрузка и анализ данных
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df_1 = pd.read_excel('/content/X_bp.xlsx', index_col=0)

df_2 = pd.read_excel('/content/X_nup.xlsx', index_col=0)

df = df_1.merge(df_2, left_index = True, right_index= True, how='inner')

df.head()

df.info()

df.describe()

plt.figure(figsize=(10,4), dpi =200)
sns.pairplot(df)

plt.figure(figsize=(15, 5))
plt.xticks(rotation =45, ha ='right')
sns.boxplot(df)

plt.figure(figsize=(15, 5), dpi = 100)
sns.heatmap(df.corr(),  cmap = 'coolwarm', annot= True)

df.corr()['Модуль упругости при растяжении, ГПа'].sort_values

df.corr()['Прочность при растяжении, МПа'].sort_values

df.shape

df.nunique()

df['Модуль упругости при растяжении, ГПа'].hist()

df['Прочность при растяжении, МПа'].hist()

df['Модуль упругости при растяжении, ГПа'].describe()

df['Прочность при растяжении, МПа'].describe()

! pip install phik

import phik
from phik.report import plot_correlation_matrix
from phik import report

phik_overview = df.phik_matrix()

phik_overview

sns.heatmap(phik_overview)

phik_overview['Модуль упругости при растяжении, ГПа'].sort_values(ascending = False)

phik_overview['Прочность при растяжении, МПа'].sort_values(ascending = False)

sns.scatterplot(x = 'Потребление смолы, г/м2', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'модуль упругости, ГПа', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Прочность при растяжении, МПа', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Шаг нашивки', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Поверхностная плотность, г/м2', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Соотношение матрица-наполнитель', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Плотность, кг/м3', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Количество отвердителя, м.%', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Содержание эпоксидных групп,%_2', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Температура вспышки, С_2', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Плотность нашивки', y = 'Модуль упругости при растяжении, ГПа', data=df)

sns.scatterplot(x = 'Угол нашивки, град', y = 'Модуль упругости при растяжении, ГПа', data=df)

# Прочность при растяжении, МПа

sns.scatterplot(x = 'Потребление смолы, г/м2', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'модуль упругости, ГПа', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Соотношение матрица-наполнитель', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Шаг нашивки', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Поверхностная плотность, г/м2', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Модуль упругости при растяжении, ГПа', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Плотность, кг/м3', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Количество отвердителя, м.%', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Содержание эпоксидных групп,%_2', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Температура вспышки, С_2', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Плотность нашивки', y = 'Прочность при растяжении, МПа', data=df)

sns.scatterplot(x = 'Угол нашивки, град', y = 'Прочность при растяжении, МПа', data=df)

df['Прочность при растяжении, МПа'].value_counts()

df['Модуль упругости при растяжении, ГПа'].value_counts()

df['Угол нашивки, град'].value_counts()

"""## Выбросы по всем параметрам"""

df.columns

plt.figure(figsize=(15,5))
sns.boxplot(df['Модуль упругости при растяжении, ГПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Соотношение матрица-наполнитель'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Плотность, кг/м3'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['модуль упругости, ГПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Количество отвердителя, м.%'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Содержание эпоксидных групп,%_2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Температура вспышки, С_2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Поверхностная плотность, г/м2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Прочность при растяжении, МПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Потребление смолы, г/м2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Шаг нашивки'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Плотность нашивки'])
plt.show()

"""# 2 удаление выбросов

"""

np.percentile(df['Модуль упругости при растяжении, ГПа'],[25,75])
np.percentile(df['Модуль упругости при растяжении, ГПа'],[25])
q75, q25 = np.percentile(df['Модуль упругости при растяжении, ГПа'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Модуль упругости при растяжении, ГПа"] < b) & (df["Модуль упругости при растяжении, ГПа"] > a)]
df = df_1
df.shape

np.percentile(df['Соотношение матрица-наполнитель'],[25,75])
np.percentile(df['Соотношение матрица-наполнитель'],[25])
q75, q25 = np.percentile(df['Соотношение матрица-наполнитель'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Соотношение матрица-наполнитель"] < b) & (df["Соотношение матрица-наполнитель"] > a)]
df = df_1
df.shape

np.percentile(df['Плотность, кг/м3'],[25,75])
np.percentile(df['Плотность, кг/м3'],[25])
q75, q25 = np.percentile(df['Плотность, кг/м3'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Плотность, кг/м3"] < b) & (df["Плотность, кг/м3"] > a)]

df = df_1
df.shape

np.percentile(df['модуль упругости, ГПа'],[25,75])
np.percentile(df['модуль упругости, ГПа'],[25])
q75, q25 = np.percentile(df['модуль упругости, ГПа'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["модуль упругости, ГПа"] < b) & (df["модуль упругости, ГПа"] > a)]
df = df_1
df.shape

np.percentile(df['Количество отвердителя, м.%'],[25,75])
np.percentile(df['Количество отвердителя, м.%'],[25])
q75, q25 = np.percentile(df['Количество отвердителя, м.%'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Количество отвердителя, м.%"] < b) & (df["Количество отвердителя, м.%"] > a)]
df = df_1
df.shape

np.percentile(df['Температура вспышки, С_2'],[25,75])
np.percentile(df['Температура вспышки, С_2'],[25])
q75, q25 = np.percentile(df['Температура вспышки, С_2'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Температура вспышки, С_2"] < b) & (df["Температура вспышки, С_2"] > a)]
_
df = df_1
df.shape

np.percentile(df['Поверхностная плотность, г/м2'],[25,75])
np.percentile(df['Поверхностная плотность, г/м2'],[25])
q75, q25 = np.percentile(df['Поверхностная плотность, г/м2'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Поверхностная плотность, г/м2"] < b) & (df["Поверхностная плотность, г/м2"] > a)]

df = df_1
df.shape

np.percentile(df['Прочность при растяжении, МПа'],[25,75])
np.percentile(df['Прочность при растяжении, МПа'],[25])
q75, q25 = np.percentile(df['Прочность при растяжении, МПа'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Прочность при растяжении, МПа"] < b) & (df["Прочность при растяжении, МПа"] > a)]

df = df_1
df.shape

np.percentile(df['Потребление смолы, г/м2'],[25,75])
np.percentile(df['Потребление смолы, г/м2'],[25])
q75, q25 = np.percentile(df['Потребление смолы, г/м2'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Потребление смолы, г/м2"] < b) & (df["Потребление смолы, г/м2"] > a)]

df = df_1
df.shape

np.percentile(df['Шаг нашивки'],[25,75])
np.percentile(df['Шаг нашивки'],[25])
q75, q25 = np.percentile(df['Шаг нашивки'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Шаг нашивки"] < b) & (df["Шаг нашивки"] > a)]

df = df_1
df.shape

np.percentile(df['Плотность нашивки'],[25,75])
np.percentile(df['Плотность нашивки'],[25])
q75, q25 = np.percentile(df['Плотность нашивки'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Плотность нашивки"] < b) & (df["Плотность нашивки"] > a)]

df = df_1
df.shape

np.percentile(df['Содержание эпоксидных групп,%_2'],[25,75])
np.percentile(df['Содержание эпоксидных групп,%_2'],[25])
q75, q25 = np.percentile(df['Содержание эпоксидных групп,%_2'],[75,25])
iqr = q75 - q25
1.5*iqr
q25 - 1.5*iqr # нижняя граница
q75 +1.5*iqr
a = q25 - 1.5*iqr
b = q75 +1.5*iqr
df_1 = df[(df["Содержание эпоксидных групп,%_2"] < b) & (df["Содержание эпоксидных групп,%_2"] > a)]

df = df_1
df.shape

"""#  3 Смотрим на данные после обработки




"""

plt.figure(figsize=(15,5))
sns.boxplot(df['Модуль упругости при растяжении, ГПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Соотношение матрица-наполнитель'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Плотность, кг/м3'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['модуль упругости, ГПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Количество отвердителя, м.%'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Содержание эпоксидных групп,%_2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Температура вспышки, С_2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Поверхностная плотность, г/м2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Прочность при растяжении, МПа'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Потребление смолы, г/м2'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Шаг нашивки'])
plt.show()

plt.figure(figsize=(15,5))
sns.boxplot(df['Плотность нашивки'])
plt.show()

"""# 4 Изменение параметров после удаления выбросов"""

plt.figure(figsize=(10, 8))
plt.xticks(rotation =45, ha ='right')
sns.boxplot(df)

plt.figure(figsize=(15, 5), dpi = 100)
sns.heatmap(df.corr(),  cmap = 'coolwarm', annot = True)

df.corr()['Модуль упругости при растяжении, ГПа'].sort_values

df.corr()['Прочность при растяжении, МПа'].sort_values

df.nunique() # количество уникальных значений для каждого столбца

df['Модуль упругости при растяжении, ГПа'].hist()

df['Прочность при растяжении, МПа'].hist()

df['Модуль упругости при растяжении, ГПа'].describe()

df['Прочность при растяжении, МПа'].describe()

! pip install phik

phik_overview = df.phik_matrix()

phik_overview

sns.heatmap(phik_overview)

phik_overview['Модуль упругости при растяжении, ГПа'].sort_values(ascending = False)

phik_overview['Прочность при растяжении, МПа'].sort_values(ascending = False)

"""# 5 Построение моделей для машинного обучения. Для значения "Модуль упругости при растяжении"

# Метод опорных векторов
"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.svm import SVR,LinearSVC

base_model = SVR()

base_model.fit(scaled_X_train, y_train)

base_preds= base_model.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error # метрики для задачи регрессии
mean_absolute_error (y_test, base_preds ) # в тех единицах в которых измеряется целевая перменная
np.sqrt(mean_squared_error(y_test, base_preds))
metrics.mean_squared_error(y_test, base_preds)
mean_absolute_error (y_test, base_preds )

print('SVR Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, base_preds))
print('MSE: ', metrics.mean_squared_error(y_test, base_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, base_preds)))

"""## Подбор гиперпараметров"""

param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1 ], 'kernel':[ 'linear', 'rbf','poly'], 'gamma':['scale', 'auto'], 'degree':[2,3,4],'epsilon':[0, 0.01, 0.1, 0.5, 1, 2] }

from sklearn.model_selection import GridSearchCV

svr = SVR()

grid = GridSearchCV(svr, param_grid)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print(' SVR поиск по сетке Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""# попробуем поменять гиперпараметры"""

param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1 ], 'kernel':[ 'linear', 'rbf','poly'], 'gamma':['scale', 'auto'], 'degree':[0,5, 1, 2,3,4],'epsilon':[0, 0.01, 0.1, 0.5, 1, 2] }

from sklearn.model_selection import GridSearchCV

svr = SVR()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print(' SVR поиск по сетке 10 блоков Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""# Посмотрим еще параметры увеличим колличество блоков"""

param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1 ], 'kernel':[ 'linear', 'rbf','poly'], 'gamma':['scale', 'auto'], 'degree':[0,5, 1, 2,3,4],'epsilon':[ 0.1, 0.5, 1, 2, 4 ,6] }

from sklearn.model_selection import GridSearchCV

svr = SVR()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=15, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print(' SVR поиск по сетке 15 блоков Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""# Уменьшим количество блоков"""

param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1 ], 'kernel':[ 'linear', 'rbf','poly'], 'gamma':['scale', 'auto'], 'degree':[0,5, 1, 2,3,4],'epsilon':[0, 0.01, 0.1, 0.5, 1, 2] }

from sklearn.model_selection import GridSearchCV

svr = SVR()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print(' SVR  поиск по сетке 5 блоков Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""# Дерево решений"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

dtree.fit(scaled_X_train , y_train)

predictions = dtree.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error

mean_absolute_error (y_test, predictions )

np.sqrt(mean_squared_error(y_test, predictions))

mean_squared_error(y_test, predictions)
mean_absolute_error (y_test, predictions ) # в тех единицах в которых измеряется целевая перменная
np.sqrt(mean_squared_error(y_test, predictions))

y_test.mean() # с этим сравним

print('дерево решений Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, predictions))
print('MSE: ', metrics.mean_squared_error(y_test, predictions))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

"""# Подбор гиперпараметров"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = DecisionTreeRegressor()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('Дерево решений поиск по сетке 5 блоков...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## подбор гиперпараметров дерево решений 10 блоков"""

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = DecisionTreeRegressor()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('Дерево решений поиск по сетке 10 блоков...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""# Лес деревьев"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

rfc.fit(scaled_X_train, y_train)

predict = rfc.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error

mean_absolute_error (y_test, predict )

np.sqrt(mean_squared_error(y_test, predict))

mean_squared_error(y_test, predict)
mean_absolute_error (y_test, predict) # в тех единицах в которых измеряется целевая перменная
np.sqrt(mean_squared_error(y_test, predict))

y_test.mean() # с этим сравним

print('Лес деревьев Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, predict))
print('MSE: ', metrics.mean_squared_error(y_test, predict))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, predict)))

"""# лес деревьев гиперпараметры 10 блоков"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = RandomForestRegressor(n_estimators=200)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('лес деревьев поиск по сетке 10 блоков Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## Лес деревьев гиперпараметры 5"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

param_grid = {
 'max_depth': [50, 60, 80, 85, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [3, 4, 5,6]



}

from sklearn.model_selection import GridSearchCV

svr = RandomForestRegressor(n_estimators=200)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('лес деревьев поиск по сетке 5 блоков Модуль упругости при растяжении, ГПа ...')

print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## KNN метод ближайших соседей"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=1)

knn.fit(scaled_X_train,y_train)

pred =knn.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_squared_error(y_test, pred)
mean_absolute_error (y_test, pred )
np.sqrt(mean_squared_error(y_test, pred))

y_test.mean() # с этим сравним

print('К ближайших лес деревьев......')
print('MAE: ', metrics.mean_absolute_error(y_test, pred))
print('MSE: ', metrics.mean_squared_error(y_test, pred))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, pred)))

"""# Подбор гиперпараметров"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor()

from sklearn.model_selection import GridSearchCV
parameters = {"n_neighbors": range(1, 50)}
gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)
gridsearch.fit(scaled_X_train, y_train)

gridsearch.best_params_

from sklearn.model_selection import GridSearchCV

svr = KNeighborsRegressor(n_neighbors =47)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

train_preds_grid = gridsearch.predict(scaled_X_test)

train_preds_grid

mean_absolute_error(y_test,train_preds_grid)

np.sqrt(mean_squared_error(y_test, train_preds_grid))

y_test.mean()

print('KNN поиск по сетке ...')
print('MAE: ', metrics.mean_absolute_error(y_test, train_preds_grid))
print('MSE: ', metrics.mean_squared_error(y_test, train_preds_grid))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, train_preds_grid)))

"""#  6 Модели для параметра Прочность при растяжении, МПа

## Метод опорных векторов для регрессии
"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.svm import SVR,LinearSVC

base_model = SVR()

base_model.fit(scaled_X_train, y_train)

base_preds= base_model.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error # метрики для задачи регрессии
mean_absolute_error (y_test, base_preds ) # в тех единицах в которых измеряется целевая перменная
np.sqrt(mean_squared_error(y_test, base_preds))
metrics.mean_squared_error(y_test, base_preds)
mean_absolute_error (y_test, base_preds )

y_test.mean() # с этим сравним

print('SVR  Прочность при растяжении, МПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, base_preds))
print('MSE: ', metrics.mean_squared_error(y_test, base_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, base_preds)))

"""## Подбор гиперпараметров"""

from sklearn.svm import SVR,LinearSVC

base_model = SVR()

param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1 ], 'kernel':[ 'linear', 'rbf','poly'], 'gamma':['scale', 'auto'], 'degree':[2,3,4],'epsilon':[0, 0.01, 0.1, 0.5, 1, 2] }

from sklearn.model_selection import GridSearchCV

svr = SVR()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

y_test.mean() # с этим сравним

grid_preds = grid.predict(scaled_X_test)

grid_preds

from sklearn.metrics import mean_absolute_error, mean_squared_error

mean_absolute_error(y_test, grid_preds)

print('SVR ...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## Дерево решений"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

dtree.fit(scaled_X_train , y_train)

predictions = dtree.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error

mean_absolute_error (y_test, predictions )

np.sqrt(mean_squared_error(y_test, predictions))

mean_squared_error(y_test, predictions)
mean_absolute_error (y_test, predictions ) # в тех единицах в которых измеряется целевая перменная
np.sqrt(mean_squared_error(y_test, predictions))

y_test.mean() # с этим сравним

print('дерево ...')
print('MAE: ', metrics.mean_absolute_error(y_test, predictions))
print('MSE: ', metrics.mean_squared_error(y_test, predictions))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

"""# Подбор гиперпараметров"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = DecisionTreeRegressor()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('Дерево решений 5 блоков..')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## увеличим количество блоков"""

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = DecisionTreeRegressor()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('Дерево решений 10 блоков...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## Лес деревьев"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

rfc.fit(scaled_X_train ,y_train)

rfc_pred = rfc.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_squared_error(y_test, rfc_pred )
mean_absolute_error (y_test, rfc_pred )
np.sqrt(mean_squared_error(y_test, rfc_pred ))

print('Лес деревьев ...')
print('MAE: ', metrics.mean_absolute_error(y_test, rfc_pred))
print('MSE: ', metrics.mean_squared_error(y_test, rfc_pred))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, rfc_pred)))

"""## Подбор гиперпараметров"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = RandomForestRegressor(n_estimators=200)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('лес деревьев 5 блоков...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = RandomForestRegressor(n_estimators=200)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('лес деревьев 10 блоков..')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""## KNN метод ближайших соседей








"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=1)

knn.fit(scaled_X_train,y_train)

pred =knn.predict(scaled_X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_squared_error(y_test, pred)
mean_absolute_error (y_test, pred )
np.sqrt(mean_squared_error(y_test, pred))

y_test.mean() # с этим сравним

print('К ближайших...')
print('MAE: ', metrics.mean_absolute_error(y_test, pred))
print('MSE: ', metrics.mean_squared_error(y_test, pred))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, pred)))

"""# Подбор гиперпараметров"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor()

from sklearn.model_selection import GridSearchCV
parameters = {"n_neighbors": range(1, 50)}
gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)
gridsearch.fit(scaled_X_train, y_train)

gridsearch.best_params_

from sklearn.model_selection import GridSearchCV

svr = KNeighborsRegressor(n_neighbors =23)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

train_preds_grid = gridsearch.predict(scaled_X_test)

train_preds_grid

mean_absolute_error(y_test,train_preds_grid)

np.sqrt(mean_squared_error(y_test, train_preds_grid))

y_test.mean()

print('K соседи...')
print('MAE: ', metrics.mean_absolute_error(y_test, train_preds_grid))
print('MSE: ', metrics.mean_squared_error(y_test, train_preds_grid))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, train_preds_grid)))

"""# 7 Модели  'Модуль упругости при растяжении, ГПа' по данным  без удаления выбросов

"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df_1 = pd.read_excel('/content/X_bp.xlsx', index_col=0)

df_2 = pd.read_excel('/content/X_nup.xlsx', index_col=0)

df = df_1.merge(df_2, left_index = True, right_index= True, how='inner')

"""#  Лес деревьев с гиперпараметрами"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(n_estimators=200)

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = RandomForestRegressor(n_estimators=200)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('лес деревьев поиск по сетке 10 блоков Модуль упругости при растяжении, ГПа...')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""#   Метод ближайших соседей с гипепараметра



"""

X = df.drop('Модуль упругости при растяжении, ГПа', axis=1)
y =df['Модуль упругости при растяжении, ГПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor()

from sklearn.model_selection import GridSearchCV
parameters = {"n_neighbors": range(1, 50)}
gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)
gridsearch.fit(scaled_X_train, y_train)

gridsearch.best_params_

from sklearn.model_selection import GridSearchCV

svr = KNeighborsRegressor(n_neighbors =34)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

train_preds_grid = gridsearch.predict(scaled_X_test)

train_preds_grid

mean_absolute_error(y_test,train_preds_grid)

np.sqrt(mean_squared_error(y_test, train_preds_grid))

y_test.mean()

print('KNN поиск по сетке ...')
print('MAE: ', metrics.mean_absolute_error(y_test, train_preds_grid))
print('MSE: ', metrics.mean_squared_error(y_test, train_preds_grid))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, train_preds_grid)))

df.columns

"""#   Дерево решений с гиперпараметрами Прочность при растяжении, МПа"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor()

param_grid = {
 'max_depth': [80, 90, 100, None],
 'max_features': ["sqrt", "log2", None],
 'min_samples_leaf': [1, 3, 5],
 'min_samples_split': [2, 3, 4],



}

from sklearn.model_selection import GridSearchCV

svr = DecisionTreeRegressor()

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=5, verbose =1)

grid.fit(scaled_X_train, y_train)

grid.best_params_

grid_preds = grid.predict(scaled_X_test)

mean_absolute_error(y_test,grid_preds)

np.sqrt(mean_squared_error(y_test, grid_preds))

y_test.mean()

print('Дерево решений 5 блоков..')
print('MAE: ', metrics.mean_absolute_error(y_test, grid_preds))
print('MSE: ', metrics.mean_squared_error(y_test, grid_preds))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, grid_preds)))

"""#  Метод ближайших соседей"""

X = df.drop('Прочность при растяжении, МПа', axis=1)
y =df['Прочность при растяжении, МПа']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.3, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor()

from sklearn.model_selection import GridSearchCV
parameters = {"n_neighbors": range(1, 50)}
gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)
gridsearch.fit(scaled_X_train, y_train)

gridsearch.best_params_

from sklearn.model_selection import GridSearchCV

svr = KNeighborsRegressor(n_neighbors =44)

grid = GridSearchCV(svr, param_grid=param_grid, scoring ='neg_mean_squared_error', cv=10, verbose =1)

train_preds_grid = gridsearch.predict(scaled_X_test)

train_preds_grid

mean_absolute_error(y_test,train_preds_grid)

np.sqrt(mean_squared_error(y_test, train_preds_grid))

y_test.mean()

print('K соседи...')
print('MAE: ', metrics.mean_absolute_error(y_test, train_preds_grid))
print('MSE: ', metrics.mean_squared_error(y_test, train_preds_grid))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, train_preds_grid)))

"""# 8  Модель созданная с помощью CatBoots для параметра "Модуль упругости при растяжении"
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df_1 = pd.read_excel('/content/X_bp.xlsx', index_col=0)

df_2 = pd.read_excel('/content/X_nup.xlsx', index_col=0)

df = df_1.merge(df_2, left_index = True, right_index= True, how='inner')

df.head()

"""# Валидационная выборка"""

from sklearn.model_selection import train_test_split
train, test = train_test_split(df, train_size=0.6, random_state =42)

len(train)/ len(df)

val, test = train_test_split(test, train_size=0.5, random_state =42)

len(test)/ len(df)

len(val)/ len(df)

"""# Подготовка признаков"""

train.columns

X = ['Соотношение матрица-наполнитель', 'Плотность, кг/м3',
       'модуль упругости, ГПа', 'Количество отвердителя, м.%',
       'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2',
       'Поверхностная плотность, г/м2',
       'Прочность при растяжении, МПа', 'Потребление смолы, г/м2',
       'Шаг нашивки', 'Плотность нашивки','Угол нашивки, град']
y =['Модуль упругости при растяжении, ГПа']

"""# запуск catboost"""

! pip install catboost

from catboost import CatBoostRegressor

model = CatBoostRegressor( eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train[X], train[y], eval_set=(val[X], val[y]))

model.predict(test[X])

test['Модуль_pred'] =model.predict(test[X])

test

from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error

from sklearn import metrics

mean_absolute_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred'])

mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred'])

np.sqrt(metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred']))

print('MAE:', metrics.mean_absolute_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred']))
print('MSE:', metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred']))
print('RMSE:',np.sqrt(metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred'])))

def error(y_true, y_pred):
  print(mean_absolute_error(y_true, y_pred))
  print(mean_absolute_percentage_error(y_true, y_pred))

error(test['Модуль упругости при растяжении, ГПа'], test['Модуль_pred'])

"""# Настройки для обучения"""

X = ['Соотношение матрица-наполнитель', 'Плотность, кг/м3',
       'модуль упругости, ГПа', 'Количество отвердителя, м.%',
       'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2',
       'Поверхностная плотность, г/м2',
       'Прочность при растяжении, МПа', 'Потребление смолы, г/м2',
       'Шаг нашивки', 'Плотность нашивки','Угол нашивки, град']
y =['Модуль упругости при растяжении, ГПа']

model = CatBoostRegressor(learning_rate= 0.01, eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train[X], train[y], eval_set=(val[X], val[y]))

X = ['Соотношение матрица-наполнитель', 'Плотность, кг/м3',
       'модуль упругости, ГПа', 'Количество отвердителя, м.%',
       'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2',
       'Поверхностная плотность, г/м2',
       'Прочность при растяжении, МПа', 'Потребление смолы, г/м2',
       'Шаг нашивки', 'Плотность нашивки','Угол нашивки, град']
y =['Модуль упругости при растяжении, ГПа']

model = CatBoostRegressor(early_stopping_rounds=200, eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train[X], train[y], eval_set=(val[X], val[y]))

"""# Обучаемся на всех данных"""

len(train)

len(val)

# объединим
pd.concat([train,val])

train_full =pd.concat([train,val])



X = ['Соотношение матрица-наполнитель', 'Плотность, кг/м3',
       'модуль упругости, ГПа', 'Количество отвердителя, м.%',
       'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2',
       'Поверхностная плотность, г/м2',
       'Прочность при растяжении, МПа', 'Потребление смолы, г/м2',
       'Шаг нашивки', 'Плотность нашивки','Угол нашивки, град']
y =['Модуль упругости при растяжении, ГПа']

model = CatBoostRegressor(learning_rate= 0.01, eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train[X], train[y], eval_set=(val[X], val[y]))

model.best_iteration_

model = CatBoostRegressor(iterations=model.best_iteration_+1,learning_rate= 0.01, eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train_full[X], train_full[y])

model.predict(test[X])

test['Модуль упругости при растяжении, ГПа_весь']= model.predict(test[X])

mean_absolute_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь'])

mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь'])

np.sqrt(metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь']))

print('MAE:', metrics.mean_absolute_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь']))
print('MSE:', metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь']))
print('RMSE:',np.sqrt(metrics.mean_squared_error(test['Модуль упругости при растяжении, ГПа'], test['Модуль упругости при растяжении, ГПа_весь'])))

X = ['Соотношение матрица-наполнитель', 'Плотность, кг/м3',
       'модуль упругости, ГПа', 'Количество отвердителя, м.%',
       'Содержание эпоксидных групп,%_2', 'Температура вспышки, С_2',
       'Поверхностная плотность, г/м2',
       'Прочность при растяжении, МПа', 'Потребление смолы, г/м2',
       'Шаг нашивки', 'Плотность нашивки','Угол нашивки, град']
y =['Модуль упругости при растяжении, ГПа']

model = CatBoostRegressor(loss_function='MAE',learning_rate= 0.01, eval_metric='RMSE',verbose=100, random_seed=42)

model.fit(train[X], train[y], eval_set=(val[X], val[y]))

"""# Анализ ошибок"""

test

test['Модуль_pred']-test['Модуль упругости при растяжении, ГПа']

test['error'] = test['Модуль_pred']-test['Модуль упругости при растяжении, ГПа']

test

test['error'].hist()

test['error'].mean()

model.get_feature_importance(prettified=True) # смотрим главные параметры

"""# 9 Нейронная сеть для предсказания Матрица + наполнитель"""

from tensorflow import keras
from tensorflow.keras import layers

from keras.models import Model
from keras.layers import Input, Dense
import matplotlib.pyplot as plt

df = df.copy()

import tensorflow as tf


train_df = df.sample(frac=0.7, random_state=4)
val_df = df.drop(train_df.index)

train_data = train_df.drop('Соотношение матрица-наполнитель',axis=1)
train_targets = val_df.drop('Соотношение матрица-наполнитель',axis=1)
test_data = train_df['Соотношение матрица-наполнитель']
test_targets = val_df['Соотношение матрица-наполнитель']



input_shape = [train_data.shape[1]]

train_data.shape

train_targets.shape

test_targets.shape

test_data.shape

train_data

train_targets

test_targets

test_data

df['Соотношение матрица-наполнитель'].describe()

mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data  /=std
train_targets -= mean
train_targets /= std

def build_model():
  model = keras.Sequential([
      layers.Dense(64, activation ='relu'),
      layers.Dense(64, activation = 'relu'),
      layers.Dense(1)
  ])
  model.compile(optimizer = 'rmsprop', loss ='mse', metrics =['mae'])
  return model

"""# перекрестная проверка по К блокам"""

k = 4
num_val_samples = len(train_data)// k
num_epochs = 50
all_scores = []
for i in range(k):
  print(f'Processing fold#{i}')
  val_data = train_data[i*num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data [i * num_val_samples: (i + 1) * num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1) * num_val_samples:]],
      axis=0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1) * num_val_samples:]],
      axis = 0)
  model = build_model()
  model.fit(partial_train_data, partial_test_data, epochs= num_epochs, batch_size=16, verbose=0)
  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
  all_scores.append(val_mae)

all_scores

np.mean(all_scores)

val_targets.describe()

"""## Попробуем увеличить время обученя модели до 100 эпох."""

num_epochs = 100
all_mae_histories = []
for i in range(k):
  print(f'Processing fold #{i}')
  val_data = train_data[i * num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data[i * num_val_samples: (i + 1)* num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1)* num_val_samples:]],
      axis =0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1)* num_val_samples:]],
      axis=0)
  model = build_model()
  history = model.fit(partial_train_data, partial_test_data, validation_data=(val_data, val_targets),
                      epochs = num_epochs, batch_size=16, verbose =0)
  mae_history= history.history['val_mae']
  all_mae_histories.append(mae_history)

all_scores

np.mean(all_scores)

model = build_model()
model.fit(train_data, test_data,epochs =100, batch_size =16, verbose =0)
test_mse_score, test_mae_score = model.evaluate(train_targets, test_targets)

test_mae_score

"""# Создание истории средних оценок"""

averate_mae_history = [
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

"""# График с оценками проверок"""

plt.plot(range(1, len(averate_mae_history) + 1), averate_mae_history)
plt.xlabel('Эпохи')
plt.ylabel('Оценка MAE')
plt.show()

from os import truncate
truncated_mae_history = averate_mae_history[10:]
plt.plot(range(1, len(truncated_mae_history)+ 1), truncated_mae_history)
plt.xlabel('Эпохи')
plt.ylabel('Оценка MAE')
plt.show()

model = build_model()
model.fit(train_data, test_data,epochs =100, batch_size =16, verbose =0)
test_mse_score, test_mae_score = model.evaluate(train_targets, test_targets)

test_mae_score

"""# Создание модели с выходным слоем функцией sigmoid и оптимизатор Adam"""

def build_model():
  model = keras.Sequential([
      layers.Dense(128, activation ='relu'),
      layers.Dense(128, activation = 'relu'),
      layers.Dense(16, activation = 'sigmoid')
  ])
  model.compile(optimizer = 'Adam', loss ='mse', metrics =['mae'])
  return model

"""# перекрестная проверка по К блокам"""

k = 5
num_val_samples = len(train_data)// k
num_epochs = 100
all_scores = []
for i in range(k):
  print(f'Processing fold#{i}')
  val_data = train_data[i*num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data [i * num_val_samples: (i + 1) * num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1) * num_val_samples:]],
      axis=0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1) * num_val_samples:]],
      axis = 0)
  model = build_model()
  model.fit(partial_train_data, partial_test_data, epochs= num_epochs, batch_size=16, verbose=0)
  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
  all_scores.append(val_mae)

all_scores

np.mean(all_scores)

val_targets.describe()

num_epochs = 200
all_mae_histories = []
for i in range(k):
  print(f'Processing fold #{i}')
  val_data = train_data[i * num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data[i * num_val_samples: (i + 1)* num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1)* num_val_samples:]],
      axis =0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1)* num_val_samples:]],
      axis=0)
  model = build_model()
  history = model.fit(partial_train_data, partial_test_data, validation_data=(val_data, val_targets),
                      epochs = num_epochs, batch_size=16, verbose =0)
  mae_history= history.history['val_mae']
  all_mae_histories.append(mae_history)

all_scores

np.mean(all_scores)

def build_model():
  model = keras.Sequential([
      layers.Dense(128, activation ='relu'),
      layers.Dense(128, activation = 'relu'),
      layers.Dense(1)
  ])
  model.compile(optimizer = 'Adam', loss ='mse', metrics =['mae'])
  return model

"""# перекрестная проверка по К блокам"""

k = 4
num_val_samples = len(train_data)// k
num_epochs = 100
all_scores = []
for i in range(k):
  print(f'Processing fold#{i}')
  val_data = train_data[i*num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data [i * num_val_samples: (i + 1) * num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1) * num_val_samples:]],
      axis=0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1) * num_val_samples:]],
      axis = 0)
  model = build_model()
  model.fit(partial_train_data, partial_test_data, epochs= num_epochs, batch_size=16, verbose=0)
  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
  all_scores.append(val_mae)

all_scores

np.mean(all_scores)

num_epochs = 200
all_mae_histories = []
for i in range(k):
  print(f'Processing fold #{i}')
  val_data = train_data[i * num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data[i * num_val_samples: (i + 1)* num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1)* num_val_samples:]],
      axis =0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1)* num_val_samples:]],
      axis=0)
  model = build_model()
  history = model.fit(partial_train_data, partial_test_data, validation_data=(val_data, val_targets),
                      epochs = num_epochs, batch_size=16, verbose =0)
  mae_history= history.history['val_mae']
  all_mae_histories.append(mae_history)

all_scores

np.mean(all_scores)

averate_mae_history = [
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

"""# График с оценками проверок"""

plt.plot(range(1, len(averate_mae_history) + 1), averate_mae_history)
plt.xlabel('Эпохи')
plt.ylabel('Оценка MAE')
plt.show()

"""# Количестов эпох 10 и 15"""

def build_model():
  model = keras.Sequential([
      layers.Dense(128, activation ='relu'),
      layers.Dense(128, activation = 'relu'),
      layers.Dense(1)
  ])
  model.compile(optimizer = 'Adam', loss ='mse', metrics =['mae'])
  return model

"""# перекрестная проверка по К блокам"""

k = 4
num_val_samples = len(train_data)// k
num_epochs = 10
all_scores = []
for i in range(k):
  print(f'Processing fold#{i}')
  val_data = train_data[i*num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data [i * num_val_samples: (i + 1) * num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1) * num_val_samples:]],
      axis=0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1) * num_val_samples:]],
      axis = 0)
  model = build_model()
  model.fit(partial_train_data, partial_test_data, epochs= num_epochs, batch_size=16, verbose=0)
  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
  all_scores.append(val_mae)

all_scores

np.mean(all_scores)

val_targets.mean()

val_targets.describe()

num_epochs = 15
all_mae_histories = []
for i in range(k):
  print(f'Processing fold #{i}')
  val_data = train_data[i * num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data[i * num_val_samples: (i + 1)* num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1)* num_val_samples:]],
      axis =0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1)* num_val_samples:]],
      axis=0)
  model = build_model()
  history = model.fit(partial_train_data, partial_test_data, validation_data=(val_data, val_targets),
                      epochs = num_epochs, batch_size=16, verbose =0)
  mae_history= history.history['val_mae']
  all_mae_histories.append(mae_history)

all_scores

np.mean(all_scores)

averate_mae_history = [
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

"""# График с оценками проверок"""

plt.plot(range(1, len(averate_mae_history) + 1), averate_mae_history)
plt.xlabel('Эпохи')
plt.ylabel('Оценка MAE')
plt.show()

def build_model():
  model = keras.Sequential([
      layers.Dense(64, activation ='relu'),
      layers.Dense(64, activation = 'relu'),
      layers.Dense(1)
  ])
  model.compile(optimizer = 'Adam', loss ='mse', metrics =['mae'])
  return model

"""# перекрестная проверка по К блокам"""

k = 4
num_val_samples = len(train_data)// k
num_epochs = 10
all_scores = []
for i in range(k):
  print(f'Processing fold#{i}')
  val_data = train_data[i*num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data [i * num_val_samples: (i + 1) * num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1) * num_val_samples:]],
      axis=0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1) * num_val_samples:]],
      axis = 0)
  model = build_model()
  model.fit(partial_train_data, partial_test_data, epochs= num_epochs, batch_size=16, verbose=0)
  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
  all_scores.append(val_mae)

all_scores

np.mean(all_scores)

val_targets.mean()

val_targets.describe()

num_epochs = 15
all_mae_histories = []
for i in range(k):
  print(f'Processing fold #{i}')
  val_data = train_data[i * num_val_samples: (i + 1)* num_val_samples]
  val_targets = test_data[i * num_val_samples: (i + 1)* num_val_samples]
  partial_train_data = np.concatenate(
      [train_data[:i * num_val_samples],
       train_data[(i + 1)* num_val_samples:]],
      axis =0)
  partial_test_data = np.concatenate(
      [test_data[:i * num_val_samples],
       test_data[(i + 1)* num_val_samples:]],
      axis=0)
  model = build_model()
  history = model.fit(partial_train_data, partial_test_data, validation_data=(val_data, val_targets),
                      epochs = num_epochs, batch_size=16, verbose =0)
  mae_history= history.history['val_mae']
  all_mae_histories.append(mae_history)

all_scores

np.mean(all_scores)

averate_mae_history = [
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

"""# График с оценками проверок"""

plt.plot(range(1, len(averate_mae_history) + 1), averate_mae_history)
plt.xlabel('Эпохи')
plt.ylabel('Оценка MAE')
plt.show()

model = build_model()
model.fit(train_data, test_data,epochs =100, batch_size =16, verbose =0)
test_mse_score, test_mae_score = model.evaluate(train_targets, test_targets)

test_mae_score











